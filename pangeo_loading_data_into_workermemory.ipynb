{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from numpy import pi, sin, cos, arccos, clip, deg2rad\n",
    "import numpy.ma as ma\n",
    "from datetime import datetime\n",
    "import dask\n",
    "import time\n",
    "import zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gcsfs\n",
    "gcs = gcsfs.GCSFileSystem()\n",
    "import os\n",
    "SCRATCH_BUCKET = os.environ['PANGEO_SCRATCH']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Equally structured datasets stored in several zarr-stores.\n",
    "All datasets have 5 columns (like the example below), each with shape = (~2105319,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2105319\n",
    "ds = xr.Dataset(\n",
    "    data_vars = dict(\n",
    "        Mean = ( [\"i\", \"pressure\"], np.random.uniform(0, 2, n).reshape(n,1) ),\n",
    "        Anomalies = ( [\"i\", \"pressure\"], np.random.uniform(-1, 5, n).reshape(n,1) ),\n",
    "    ),\n",
    "    coords=dict(\n",
    "        time = ( [\"i\"], np.random.uniform(13000, 18500, n) ),\n",
    "        latitude = ( [\"i\"], np.random.uniform(-80, 80, n) ),\n",
    "        longitude = ( [\"i\"], np.random.uniform(-180, 180, n) ),\n",
    "        pressure = ([\"pressure\"], np.array([50]) ),\n",
    "    ),\n",
    "    attrs=dict(\n",
    "        description = 'Description',\n",
    "        pindex = 4,\n",
    "        number_of_harmonics = 2,\n",
    "        window_size = 500e3,\n",
    "        creation_date = str( datetime.now() )\n",
    "    ),\n",
    ")\n",
    "\n",
    "ds.time.attrs[\"standard_name\"] = 'time'\n",
    "ds.time.attrs[\"units\"] = 'days since 1970-01-01 00:00:00'\n",
    "ds.latitude.attrs[\"standard_name\"] = 'latitude'\n",
    "ds.latitude.attrs[\"units\"] = 'degrees_north'\n",
    "ds.longitude.attrs[\"standard_name\"] = 'longitude'\n",
    "ds.longitude.attrs[\"units\"] = 'degrees_east'\n",
    "ds.pressure.attrs[\"standard_name\"] = 'pressure'\n",
    "ds.pressure.attrs[\"units\"] = 'decibar'\n",
    "ds.Mean.attrs[\"standard_name\"] = 'Estimated mean dynamic height'\n",
    "ds.Mean.attrs[\"units\"] = 'm^2/s^2'\n",
    "ds.Anomalies.attrs[\"standard_name\"] = 'dynamic height anomalies'\n",
    "ds.Anomalies.attrs[\"units\"] = 'm^2/s^2'\n",
    "\n",
    "dsc = ds.chunk()\n",
    "path_to_zarrstore = f'{SCRATCH_BUCKET}/dataset.zarr'\n",
    "mapper_alt1 = gcs.get_mapper(path_to_zarrstore)\n",
    "dsc.to_zarr(mapper_alt1, consolidated=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Dataset.info of <xarray.Dataset>\n",
       "Dimensions:    (i: 2105319, pressure: 1)\n",
       "Coordinates:\n",
       "    time       (i) float64 dask.array<chunksize=(2105319,), meta=np.ndarray>\n",
       "    latitude   (i) float64 dask.array<chunksize=(2105319,), meta=np.ndarray>\n",
       "    longitude  (i) float64 dask.array<chunksize=(2105319,), meta=np.ndarray>\n",
       "  * pressure   (pressure) int64 50\n",
       "Dimensions without coordinates: i\n",
       "Data variables:\n",
       "    Mean       (i, pressure) float64 dask.array<chunksize=(2105319, 1), meta=np.ndarray>\n",
       "    Anomalies  (i, pressure) float64 dask.array<chunksize=(2105319, 1), meta=np.ndarray>\n",
       "Attributes:\n",
       "    description:          Description\n",
       "    pindex:               4\n",
       "    number_of_harmonics:  2\n",
       "    window_size:          500000.0\n",
       "    creation_date:        2023-07-28 10:52:19.703490>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsc.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Size of each dataset in megabytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.212768"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsc.nbytes/1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Connect to a dask-cluster and set cluster-options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask_gateway import GatewayCluster, Gateway\n",
    "from distributed import Client\n",
    "\n",
    "g = Gateway()\n",
    "g.list_clusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster = g.connect(g.list_clusters()[0].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = g.cluster_options()\n",
    "options.worker_cores = 2; options.worker_memory = 4\n",
    "# Create a cluster with those options\n",
    "cluster = g.new_cluster(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g.list_clusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-3e431539-2d3a-11ee-818c-be3e7174ebe4</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> dask_gateway.GatewayCluster</td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"/services/dask-gateway/clusters/prod.8c7a16b83dc849059cafaef8edcd6dcd/status\" target=\"_blank\">/services/dask-gateway/clusters/prod.8c7a16b83dc849059cafaef8edcd6dcd/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "            <button style=\"margin-bottom: 12px;\" data-commandlinker-command=\"dask:populate-and-launch-layout\" data-commandlinker-args='{\"url\": \"/services/dask-gateway/clusters/prod.8c7a16b83dc849059cafaef8edcd6dcd/status\" }'>\n",
       "                Launch dashboard in JupyterLab\n",
       "            </button>\n",
       "        \n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "            <div style='background-color: #f2f2f2; display: inline-block; padding: 10px; border: 1px solid #999999;'>\n",
       "  <h3>GatewayCluster</h3>\n",
       "  <ul>\n",
       "    <li><b>Name: </b>prod.8c7a16b83dc849059cafaef8edcd6dcd\n",
       "    <li><b>Dashboard: </b><a href='/services/dask-gateway/clusters/prod.8c7a16b83dc849059cafaef8edcd6dcd/status' target='_blank'>/services/dask-gateway/clusters/prod.8c7a16b83dc849059cafaef8edcd6dcd/status</a>\n",
       "  </ul>\n",
       "</div>\n",
       "\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tls://10.8.101.6:8786' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loading of data from cloud-storage<br>\n",
    "Want to load 4 out of 5 columns of data, into several dask-workers memory, and do embarrasingly parallel computations ( ~1e6  )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def load_chunksauto(mapper):\n",
    "    \"\"\"Load data from zarr-store into worker-memory\"\"\"\n",
    "    \n",
    "    ds = xr.open_zarr(mapper, consolidated=True, chunks='auto') \n",
    "    data0 = ds.Anomalies.sel(pressure=50).load() # to shape=(n,) from shape=(n,1)\n",
    "    ii = ~xr.apply_ufunc(np.isnan, data0)\n",
    "    data, lat, lon, time = data0.values[ii], ds.latitude.load().values[ii], ds.longitude.load().values[ii], ds.time.load().values[ii]\n",
    "    \n",
    "    # Calculation using data-, lat-, lon-, and time-arrays\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def load_zarr(mapper):\n",
    "    \"\"\"Load data from zarr-store into worker-memory\"\"\"\n",
    "    \n",
    "    z = zarr.open_consolidated(mapper)\n",
    "    data0 = np.squeeze(z.Anomalies[:]) # to shape=(n,) from shape=(n,1)\n",
    "    ii = ~np.isnan(data0)\n",
    "    data, lat, lon, time = data0[ii], z.latitude[:][ii], z.longitude[:][ii], z.time[:][ii]\n",
    "    \n",
    "    # Calculation using data-, lat-, lon-, and time-arrays\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def load_zarr_convenience(mapper): \n",
    "    \"\"\"Load data from zarr-store into worker-memory\"\"\"\n",
    "    \n",
    "    z = zarr.convenience.open_consolidated(mapper)\n",
    "    data0 = np.squeeze(z.Anomalies[:]) # to shape=(n,) from shape=(n,1)\n",
    "    ii = ~np.isnan(data0)\n",
    "    data, lat, lon, time = data0[ii], z.latitude[:][ii], z.longitude[:][ii], z.time[:][ii]\n",
    "    \n",
    "    # Calculation using data-, lat-, lon-, and time-arrays\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Timing loading of data:<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "ds = xr.open_zarr(mapper, consolidated=True, chunks='auto'); ...  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.07 s ± 67.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit dask.compute( load_chunksauto(mapper_alt1) )[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "ds = zarr.open_consolidated(mapper); ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.01 s ± 270 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit dask.compute( load_zarr(mapper_alt1) )[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "ds = zarr.convenience.open_consolidated(mapper); ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "987 ms ± 132 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit dask.compute( load_zarr_convenience(mapper_alt1) )[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling down and closing cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The reports from the logger\n",
    "(I am not sure if these look the same for the dask-workers):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger gcsfs (DEBUG)>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fsspec.utils\n",
    "fsspec.utils.setup_logging(logger_name=\"gcsfs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-28 11:38:11,422 - gcsfs - DEBUG - _call -- GET: https://storage.googleapis.com/download/storage/v1/b/pangeo-integration-te-3eea-prod-scratch-bucket/o/ofk123%2Fdataset.zarr%2F.zmetadata?alt=media, (), {}\n",
      "2023-07-28 11:38:11,487 - gcsfs - DEBUG - _call -- GET: https://storage.googleapis.com/download/storage/v1/b/pangeo-integration-te-3eea-prod-scratch-bucket/o/ofk123%2Fdataset.zarr%2Ftime%2F0?alt=media, (), {}\n",
      "2023-07-28 11:38:11,633 - gcsfs - DEBUG - _call -- GET: https://storage.googleapis.com/download/storage/v1/b/pangeo-integration-te-3eea-prod-scratch-bucket/o/ofk123%2Fdataset.zarr%2Ftime%2F0?alt=media, (), {}\n",
      "2023-07-28 11:38:11,757 - gcsfs - DEBUG - _call -- GET: https://storage.googleapis.com/download/storage/v1/b/pangeo-integration-te-3eea-prod-scratch-bucket/o/ofk123%2Fdataset.zarr%2Fpressure%2F0?alt=media, (), {}\n"
     ]
    }
   ],
   "source": [
    "ds = xr.open_zarr(mapper_alt1, consolidated=True, chunks='auto') \n",
    "data0 = ds.Anomalies.sel(pressure=50).load() # to shape=(n,) from shape=(n,1)\n",
    "ii = ~xr.apply_ufunc(np.isnan, data0)\n",
    "data, lat, lon, time = data0.values[ii], ds.latitude.load().values[ii], ds.longitude.load().values[ii], ds.time.load().values[ii]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-28 11:28:31,766 - gcsfs - DEBUG - _call -- GET: https://storage.googleapis.com/download/storage/v1/b/pangeo-integration-te-3eea-prod-scratch-bucket/o/ofk123%2Fdataset.zarr%2F.zmetadata?alt=media, (), {}\n",
      "2023-07-28 11:28:31,839 - gcsfs - DEBUG - _call -- GET: https://storage.googleapis.com/download/storage/v1/b/pangeo-integration-te-3eea-prod-scratch-bucket/o/ofk123%2Fdataset.zarr%2FAnomalies%2F0.0?alt=media, (), {}\n",
      "2023-07-28 11:28:32,133 - gcsfs - DEBUG - _call -- GET: https://storage.googleapis.com/download/storage/v1/b/pangeo-integration-te-3eea-prod-scratch-bucket/o/ofk123%2Fdataset.zarr%2Flatitude%2F0?alt=media, (), {}\n",
      "2023-07-28 11:28:32,310 - gcsfs - DEBUG - _call -- GET: https://storage.googleapis.com/download/storage/v1/b/pangeo-integration-te-3eea-prod-scratch-bucket/o/ofk123%2Fdataset.zarr%2Flongitude%2F0?alt=media, (), {}\n",
      "2023-07-28 11:28:32,543 - gcsfs - DEBUG - _call -- GET: https://storage.googleapis.com/download/storage/v1/b/pangeo-integration-te-3eea-prod-scratch-bucket/o/ofk123%2Fdataset.zarr%2Ftime%2F0?alt=media, (), {}\n"
     ]
    }
   ],
   "source": [
    "z = zarr.open_consolidated(mapper_alt1);\n",
    "zanom0= np.squeeze(z.Anomalies[:]);\n",
    "ii= ~np.isnan(zanom0);\n",
    "zanom= zanom0[ii]; \n",
    "zlat = z.latitude[:][ii]; \n",
    "zlon=z.longitude[:][ii]; \n",
    "zt = z.time[:][ii]; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-28 11:28:33,806 - gcsfs - DEBUG - _call -- GET: https://storage.googleapis.com/download/storage/v1/b/pangeo-integration-te-3eea-prod-scratch-bucket/o/ofk123%2Fdataset.zarr%2F.zmetadata?alt=media, (), {}\n",
      "2023-07-28 11:28:33,838 - gcsfs - DEBUG - _call -- GET: https://storage.googleapis.com/download/storage/v1/b/pangeo-integration-te-3eea-prod-scratch-bucket/o/ofk123%2Fdataset.zarr%2FAnomalies%2F0.0?alt=media, (), {}\n",
      "2023-07-28 11:28:33,959 - gcsfs - DEBUG - _call -- GET: https://storage.googleapis.com/download/storage/v1/b/pangeo-integration-te-3eea-prod-scratch-bucket/o/ofk123%2Fdataset.zarr%2Flatitude%2F0?alt=media, (), {}\n",
      "2023-07-28 11:28:34,186 - gcsfs - DEBUG - _call -- GET: https://storage.googleapis.com/download/storage/v1/b/pangeo-integration-te-3eea-prod-scratch-bucket/o/ofk123%2Fdataset.zarr%2Flongitude%2F0?alt=media, (), {}\n",
      "2023-07-28 11:28:34,307 - gcsfs - DEBUG - _call -- GET: https://storage.googleapis.com/download/storage/v1/b/pangeo-integration-te-3eea-prod-scratch-bucket/o/ofk123%2Fdataset.zarr%2Ftime%2F0?alt=media, (), {}\n"
     ]
    }
   ],
   "source": [
    "z = zarr.convenience.open_consolidated(mapper_alt1)\n",
    "data0 = np.squeeze(z.Anomalies[:]) # shape=(n,) from shape=(n,1)\n",
    "ii = ~np.isnan(data0)\n",
    "data, lat, lon, time = data0[ii], z.latitude[:][ii], z.longitude[:][ii], z.time[:][ii]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
